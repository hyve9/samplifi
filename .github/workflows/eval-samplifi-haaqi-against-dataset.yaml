name: Run Samplifi on Dataset

on:
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset to download and process'
        required: true

jobs:
  run-samplifi:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Setup Miniconda
      uses: conda-incubator/setup-miniconda@v2
      with:
        auto-update-conda: true
        python-version: '3.9'  # Use Python 3.9

    - name: Create and activate Conda environment
      run: |
        echo "source $(conda info --base)/etc/profile.d/conda.sh" >> ~/.bashrc
        source ~/.bashrc
        conda env create -f environment.yml
        conda activate samplifi
        python -m pip install tensorflowjs ddsp --no-deps

    - name: Download dataset
      timeout-minutes: 180
      run: |
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate samplifi
        python download-mir-dataset.py --dataset "${{ github.event.inputs.dataset }}"

    - name: Run Samplifi
      run: |
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate samplifi
        python run-samplifi.py --dataset ${{ github.event.inputs.dataset }}

    - name: Upload CSV as artifact
      uses: actions/upload-artifact@v2
      with:
        name: samplifi-output
        path: haaqi_scores.csv # Replace with the path to your CSV file